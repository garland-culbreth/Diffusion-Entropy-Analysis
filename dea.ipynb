{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion Entropy Analysis \n",
    "\n",
    "2020-08-19 - Garland Culbreth, Jacob Baxley, David Lambert.\n",
    "\n",
    "Center for Nonlinear Science, University of North Texas.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook includes functions for performing both DEA with stripes and the original DEA without. The functions with stripes were written by G.C. with contribution from J.B. The original (no stripe) DEA function was done by J.B. and D.L., and vectorized by G.C.\n",
    "\n",
    "This is a major update of the DEA program, using Python. It's loosely based on an older Python conversion of my even older MATLAB version, which was converted by Jacob Baxley, David Lambert, and me. That conversion relied on an old module of legacy code, which was outdated and in need of refinement. For this version, I wrote a completely new function that performs the same process, but faster and using standard Python/NumPy functions.\n",
    "\n",
    "Useage instructions and documentation etc. can be found in markdown cells or function docstrings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using this notebook\n",
    "\n",
    "All work should be done in the bottom code cell, the one labeled \"Work cell\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fbm import fbm, fgn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')  # use any plt.style you like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample data  \n",
    "\n",
    "Generators for Fractional Brownian Motion and a simple Random Walk, for testing purposes. If you have no data, use these to generate some."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(length):\n",
    "    \"\"\"Generates an array of sample data.\"\"\"\n",
    "    # hurst = 0.7\n",
    "    # fGnSample = fgn(length, hurst)\n",
    "    # fBmSample = fbm(length, hurst)\n",
    "    np.random.seed(0)  # for baseline consistency\n",
    "    random_steps = np.random.choice([-1, 1], length)\n",
    "    random_steps[0] = 0  # always start from 0\n",
    "    random_walk = np.cumsum(random_steps)\n",
    "    return random_walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_data = sample_data(20000)\n",
    "\n",
    "plt.plot(some_data)\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('x(t)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_stripes(data, stripes, show_plot): \n",
    "    \"\"\"\n",
    "    Rounds `data` to `stripes` evenly spaced intervals.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array_like\n",
    "        Time-series data to be examined.\n",
    "    stripes : int\n",
    "        Number of stripes to apply. \n",
    "    show_plot : bool\n",
    "        If True, show data plot with overlaid stripes.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    rounded_data : ndarray\n",
    "        `data` rounded to `stripes` number of equally spaced intervals.\n",
    "    \"\"\"\n",
    "    \n",
    "    if show_plot == True:\n",
    "        lines = np.linspace(min(data), max(data), num=stripes)\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        plt.plot(data)\n",
    "        plt.hlines(y=lines, xmin=0, xmax=len(data))\n",
    "        plt.xlabel('t')\n",
    "        plt.ylabel('Data(t)')\n",
    "        plt.title('Data with stripes')\n",
    "        plt.show()\n",
    "    \n",
    "    if min(data) <= 0:\n",
    "        data = data + abs(min(data))\n",
    "    elif min(data) > 0:\n",
    "        data = data - abs(min(data))\n",
    "    max_data = max(data)\n",
    "    min_data = min(data)\n",
    "    data_width = abs(max_data - min_data)\n",
    "    stripe_size = data_width / stripes\n",
    "    rounded_data = data / stripe_size\n",
    "    \n",
    "    return rounded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_events(series):\n",
    "    \"\"\"Records an event (1) when `series` changes value.\"\"\"\n",
    "    events = []\n",
    "    for i in range(1, len(series)):\n",
    "        if (series[i] < np.floor(series[i-1])+1 and \n",
    "            series[i] > np.ceil(series[i-1])-1):\n",
    "            # if both true, no crossing\n",
    "            events.append(0)\n",
    "        else:\n",
    "            events.append(1)\n",
    "    np.append(events, 0)\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trajectory(events):\n",
    "    \"\"\"Constructs diffusion trajectory from events.\"\"\"\n",
    "    trajectory = np.cumsum(events)\n",
    "    return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(trajectory):\n",
    "    \"\"\"\n",
    "    Calculates the Shannon Entropy of the diffusion trajectory.\n",
    "\n",
    "    Generates a range of window lengths L. Steps each one along \n",
    "    `trajectory` and computes the displacement of `trajectory` \n",
    "    over each window position. Bins these displacements, and divides \n",
    "    by the sum of all bins to make the probability distribution `p`. \n",
    "    Puts `p` into the equation for Shannon Entropy to get s(L).\n",
    "    Repeats for all L in range `WindowLengths`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trajectory : array_like\n",
    "        Diffusion trajectory. Constructed by make_trajectory.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    s : ndarray\n",
    "        Shannon Entropy values, S(L).\n",
    "    window_lengths : ndarray\n",
    "        Window lengths, L. \n",
    "\n",
    "    Notes\n",
    "    ----------\n",
    "    `tqdm()` makes the progress bar appear.\n",
    "    \"\"\"\n",
    "    S = []\n",
    "    window_lengths = np.arange(1, int(0.25*len(trajectory)), 1)\n",
    "    for L in tqdm(window_lengths):\n",
    "        window_starts = np.arange(0, len(trajectory)-L, 1)\n",
    "        window_ends = np.arange(L, len(trajectory), 1)\n",
    "        displacements = trajectory[window_ends] - trajectory[window_starts]\n",
    "        bin_counts = np.bincount(displacements)\n",
    "        bin_counts = bin_counts[bin_counts != 0]\n",
    "        P = bin_counts / np.sum(bin_counts)\n",
    "        S.append(-np.sum(P * np.log(P)))\n",
    "    return S, window_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_stripe_entropy(trajectory):\n",
    "    \"\"\"\n",
    "    Calculates the Shannon Entropy of the diffusion trajectory.\n",
    "\n",
    "    Generates a range of window lengths L. Steps each one along \n",
    "    `trajectory` and computes the displacement of `trajectory` \n",
    "    over each window position. Bins these displacements, and divides \n",
    "    by the sum of all bins to make the probability distribution `p`. \n",
    "    Puts `p` into the equation for Shannon Entropy to get s(L).\n",
    "    Repeats for all L in range `WindowLengths`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trajectory : array_like\n",
    "        Diffusion trajectory. FOR NO STRIPES JUST PASS THE DATA SERIES.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    S : ndarray\n",
    "        Shannon Entropy values, S(L).\n",
    "    window_lengths : ndarray\n",
    "        Window lengths, L.\n",
    "\n",
    "    Notes\n",
    "    ----------\n",
    "    `tqdm()` makes the progress bar appear.\n",
    "    \"\"\"\n",
    "    window_lengths = np.arange(1, int(0.25*len(trajectory)), 1)\n",
    "    S = []\n",
    "    for L in tqdm(window_lengths):\n",
    "        window_starts = np.arange(0, len(trajectory)-L, 1)\n",
    "        window_ends = np.arange(L, len(trajectory), 1)\n",
    "        traj = trajectory[window_starts] - trajectory[window_ends]\n",
    "        counts, bin_edge = np.histogram(traj, bins='doane')  # doane least bad for nongaussian\n",
    "        counts = np.array(counts[counts != 0])\n",
    "        binsize = bin_edge[1] - bin_edge[0]\n",
    "        P = counts / sum(counts)\n",
    "        S.append(-sum(P*np.log(P)) + np.log(binsize))\n",
    "    return S, window_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaling(S, L, start, stop):\n",
    "    \"\"\"\n",
    "    Calculates scaling.\n",
    "    \n",
    "    Calculates the scaling of the time-series by performing a \n",
    "    least-squares linear fit over S(l) and ln(l).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s : array_like\n",
    "        Shannon Entropy values. \n",
    "    L : array_like\n",
    "        Window Lengths. \n",
    "    start : int\n",
    "        Index at which to start the fit slice.\n",
    "    stop : int\n",
    "        Index at which to stop the fit slice.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    L_slice : ndarray \n",
    "        The slice of window lengths L.\n",
    "    coefficients : ndarray\n",
    "        Slope and intercept of the fit. \n",
    "\n",
    "    Notes\n",
    "    ----------\n",
    "    Least-squares linear fits on log scale data have issues, \n",
    "    see doi:10.1371/journal.pone.0085777\n",
    "    Making a version that uses the `powerlaw` package instead \n",
    "    would be better...\n",
    "    \"\"\"\n",
    "    S_slice = S[start:stop]\n",
    "    L_slice = L[start:stop]\n",
    "    coefficients = np.polyfit(np.log(L_slice), S_slice, 1)\n",
    "    return L_slice, coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mu(delta):\n",
    "    \"\"\"\n",
    "    Calculates the mu.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    delta : float\n",
    "        Scaling of the time-series process. \n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    mu : float\n",
    "        Complexity parameter. Powerlaw index for inter-event \n",
    "        time distribution.\n",
    "    \"\"\"\n",
    "    mu = 1 + (1 / delta)\n",
    "    if mu > 3:\n",
    "        mu = 1 + delta\n",
    "    return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(L, S, x_interval, slope, y_intercept, mu):\n",
    "    \"\"\"testing a plotting function\"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(L, S, linestyle='', marker='.')\n",
    "    ax.plot(x_interval, slope * np.log(x_interval) + y_intercept, color='k',\n",
    "             label='$\\delta = $'+str(np.round(slope, 2)))\n",
    "    ax.plot([], [], linestyle='',label='$\\mu = $'+str(np.round(mu, 2)))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dea_no_stripes(data, start, stop):\n",
    "    \"\"\"\n",
    "    Applies DEA without the stripes refinement.\n",
    "\n",
    "    Original DEA. Takes the original time series as the diffusion \n",
    "    trajectory.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array_like\n",
    "        Time-series to be analysed.\n",
    "    start : int\n",
    "        Array index at which to start linear fit.\n",
    "    stop : int \n",
    "        Array index at which to stop linear fit.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    figure \n",
    "        A figure plotting S(l) vs. ln(l), overlaid with the fit \n",
    "        line, labelled with the scaling and mu values.\n",
    "    \"\"\"\n",
    "    S, L = no_stripe_entropy(data)\n",
    "    fit = get_scaling(S, L, start, stop)\n",
    "    mu = get_mu(fit[1][0])\n",
    "\n",
    "    fig = plt.figure(figsize = (6, 5))\n",
    "    plt.plot(L, S, linestyle='', marker='.')\n",
    "    plt.plot(fit[0], fit[1][0] * np.log(fit[0]) + fit[1][1], color='k',\n",
    "             label='$\\delta = {}$'.format(np.round(fit[1][0], 2)))\n",
    "    plt.plot([], [], linestyle='', \n",
    "             label='$\\mu = {}$'.format(np.round(mu, 2)))\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('$ln(l)$')\n",
    "    plt.ylabel('$S(l)$')\n",
    "    plt.legend(loc=0)\n",
    "    # plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dea_with_stripes(data, stripes, start, stop, data_plot):\n",
    "    \"\"\"\n",
    "    Applies DEA with the stripes refinement.\n",
    "\n",
    "    Runs a sequence of functions to apply stripes and then \n",
    "    perform DEA on the data series. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array_like\n",
    "        Time-series to be analysed.\n",
    "    stripes : int\n",
    "        Number of stripes to be applied to the data.\n",
    "    start : int\n",
    "        Array index at which to start linear fit.\n",
    "    stop : int \n",
    "        Array index at which to stop linear fit.\n",
    "    data_plot : bool\n",
    "        If True, show data plot with overlaid stripes.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    fig : figure \n",
    "        A figure plotting S(l) vs. ln(l), overlaid with the fit \n",
    "        line, labelled with the scaling and mu values.\n",
    "    \"\"\"\n",
    "    rounded_data = apply_stripes(data, stripes, data_plot)\n",
    "    event_array = find_events(rounded_data)\n",
    "    diffusion_trajectory = make_trajectory(event_array)\n",
    "    s, L = entropy(diffusion_trajectory)\n",
    "    fit = get_scaling(s, L, start, stop)\n",
    "    mu = get_mu(fit[1][0])\n",
    "\n",
    "    fig = plt.figure(figsize = (6, 5))\n",
    "    plt.plot(L, s, linestyle='', marker='.')\n",
    "    plt.plot(fit[0], fit[1][0] * np.log(fit[0]) + fit[1][1], color='k',\n",
    "             label='$\\delta = $'+str(np.round(fit[1][0], 2)))\n",
    "    plt.plot([], [], linestyle='',label='$\\mu = $'+str(np.round(mu, 2)))\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('$ln(L)$')\n",
    "    plt.ylabel('$S(L)$')\n",
    "    plt.legend(loc=0)\n",
    "    # plt.show()\n",
    "    return fig"
   ]
  },
  {
   "source": [
    "## Known mu data generating function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def known_mu_test(mu, T):\n",
    "    test_tau = np.arange(1, 1000, 1)\n",
    "    distribution = (mu-1) * ((T**(mu-1)) / ((T+test_tau)**mu))\n",
    "    waiting_times = np.random.choice(distribution, 50000)\n",
    "    event_indexes = np.ceil(1000*np.cumsum(waiting_times)).astype(int)\n",
    "    random_walk = np.random.choice([-1, 1], len(waiting_times))\n",
    "    known_mu_data = np.zeros(max(event_indexes)+1)\n",
    "    known_mu_data[event_indexes] = random_walk\n",
    "    # for i in range(1, len(known_mu_data)):\n",
    "    #     if known_mu_data[i] == 0:\n",
    "    #         known_mu_data[i] = known_mu_data[i-1]\n",
    "    # plt.plot(known_mu_data, label='$\\\\xi$(t)')\n",
    "    known_mu_data = np.cumsum(known_mu_data)\n",
    "    return known_mu_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_mu_sample = known_mu_test(mu=2.3, T=1)\n",
    "plt.plot(known_mu_sample)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Cell  \n",
    "\n",
    "Everything you need to work with is in this cell.  \n",
    "\n",
    "### Running  \n",
    " - Load your data into the `data` variable. Numpy arrays or Pandas DataFrame columns will work.  \n",
    " - Choose the number of stripes to apply, and the interval (slice) over which to fit.  \n",
    " - Run!  \n",
    " - Adjust number of stripes and slicing indexes as necessary.  \n",
    "\n",
    "### Output  \n",
    " - A progress bar will display progress and time elapsed/remaining.  \n",
    " - On completion, a figure will be drawn with the results.  \n",
    " - Interpretation of results has its own section, below.  \n",
    "\n",
    "### Choosing number of stripes  \n",
    " - Run a few initial tests with different values. e.g. 10, 50, 100.  \n",
    " - If there is significant disagreement in the scalings measured, vary about those trial numbers.  \n",
    " - The correct number of stripes to use is that number such that when varied up or down a little, the scaling does not change.  \n",
    "\n",
    "### Choosing fit interval  \n",
    " - In the result figure, if the results are good, there will be a powerlaw region that in the loglog figure appears linear. You want the fit interval to line up with this region.  \n",
    " - $S(l)$ is logged in calculation, $l$ is logged by the scale of the plot. The fitting function accounts for this.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### ----WORK HERE---- ###\n",
    "data = sample_data(20000)\n",
    "number_of_stripes = 40  # needs to be at least 2\n",
    "fit_start = 50\n",
    "fit_stop = 400\n",
    "show_data_plot = False  # makeTrue to see plot of data with stripes\n",
    "\n",
    "result = dea_with_stripes(data, number_of_stripes, fit_start, fit_stop, show_data_plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_dea_result = dea_no_stripes(data, start=50, stop=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting Results  \n",
    "\n",
    "### Basics  \n",
    " - $\\delta$ is the measured scaling of the time-series process.  \n",
    " - $\\mu$ is a complexity index, defined as the power for the inter-event time distribution $1/\\tau^{\\mu}$ ($\\tau$ being inter-event time).  \n",
    "\n",
    "### Baselines  \n",
    " - For a totally random process, DEA yields $\\delta = 0.5.$  \n",
    " - The closer $\\delta$ is to 1, and the closer $\\mu$ is to 2, the more complex the data-series is. Those are the critical values of $\\delta$ and $\\mu$.  \n",
    " - If $\\delta < 0.5$, this usually means the time-series is not complex. At least, not in this sense. \n",
    "\n",
    "### Determining $\\mu$  \n",
    " - Two ways of calculating $\\mu$ are employed:  \n",
    "   - For $1 < \\mu < 2$: $\\mu = 1 + \\delta$.  \n",
    "   - For $2 < \\mu < 3$: $\\mu = 1 + 1/\\delta$.  \n",
    " - To choose which calculation is correct, if $\\mu = 1 + 1/\\delta$ gives a $\\mu > 3$ then use $\\mu = 1 + \\delta$. The program automatically checks this and puts the recommended $\\mu$ in the figure legend.  \n",
    " - The theoretical justifications for the two methods of deriving $\\mu$ from the scaling $\\delta$ are given in Section 3.2 of Reference 1 and Section 3.1-3.2 of Reference 3.\n",
    " - If you already have an expectation for what range $\\mu$ should be in, e.g. from theoretical arguments, use that.\n",
    "     - See *Overriding $\\mu$ calculation* in *Advanced use*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced use\n",
    "\n",
    "\n",
    "### Speed and runtime\n",
    "In the function `entropy()` the range of window lengths $l$ is defined such that each is 1 larger than the previous:  \n",
    "        \n",
    "        window_lengths = np.arange(1, int(0.25*len(trajectory)), 1)  \n",
    "\n",
    "This can make the program take a long time to run if you give it a long time-series (e.g. 20000 timesteps takes ~1 second). If you want to speed up the runtime, you can increase the step size for the range, e.g.:\n",
    "\n",
    "        window_lengths = np.arange(1, int(0.25*len(trajectory)), 10)  \n",
    "\n",
    "This will still give good results, for long time-series, but can greatly speed up runtime. Akin to taking a subset of the window lengths that would have been used if the step size were 1.  \n",
    "\n",
    "Doing this also means you will have fewer values of $S(l)$ and $ln(l)$ to work with though, so be mindful.\n",
    "\n",
    "*I might make this window length step a passable variable in the future, but I'm not sure.*\n",
    "\n",
    "\n",
    "### Maximum window length\n",
    "In the function `entropy()` the range of window lengths ends at 0.25 times the length of the diffusion trajectory:\n",
    "\n",
    "        window_lengths = np.arange(1, int(0.25*len(trajectory)), 10)  \n",
    "\n",
    "You can increase further if you want, but there is usually no need. For longer window lengths $l$, and especially for $l$ longer than `0.5*len(trajectory)`, $S(l)$ quickly starts to decay and doesn't give anything useful. \n",
    "\n",
    "\n",
    "### Overriding $\\mu$ calculation\n",
    "If you have an expectation for what range $\\mu$ should be in, e.g. from theoretical arguments, then you can change the function `GetMu()` to just perform the corresponding calculation rather than check a conditional and make a recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## References  \n",
    " 1. *Entropic Approach to the Detection of Crucial Events* [doi:10.3390/e21020178](https://doi.org/10.3390/e21020178)  \n",
    "    - This paper introduced the stripes and describes their role with figure examples.\n",
    "    - Note: this paper used $\\eta$ to denote scaling, rather than $\\delta$.  \n",
    " 2. *Scaling detection in time series: Diffusion entropy analysis* [doi:10.1103/PhysRevE.66.036130](https://doi.org/10.1103/PhysRevE.66.036130)  \n",
    "    - The actual algorithm for DEA is detailed (mostly only in words) in Section IV.  \n",
    " 3. *Asymmetric anomalous diffusion: an efficient way to detect memory in time series* [doi:10.1142/S0218348X01000865](https://doi.org/10.1142/S0218348X01000865)  \n",
    "    - This paper introduced always using positive steps when constructing the event array, rather than the sign of the step at that time index."
   ]
  }
 ]
}