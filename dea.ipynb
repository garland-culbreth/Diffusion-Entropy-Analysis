{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit (conda)"
  },
  "interpreter": {
   "hash": "a6d37ef22e159a6af38b2a2fd504aec87c21a0443217d8cb2ce6b966a5400236"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Modified Diffusion Entropy Analysis \r\n",
    "\r\n",
    "Garland Culbreth, Jacob Baxley, David Lambert.  \r\n",
    "Center for Nonlinear Science, University of North Texas.  \r\n",
    "\r\n",
    "Last update: 2021-07-22"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using this notebook\r\n",
    "___\r\n",
    "\r\n",
    " - All work should be done in the bottom code cell, the one labeled \"Work cell\". \r\n",
    " - Useage instructions and documentation etc. can be found in markdown cells or function docstrings."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import seaborn as sns\r\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sns.set_theme(context='notebook',\r\n",
    "              style='ticks',\r\n",
    "              palette='deep',\r\n",
    "              font_scale=1.2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data\n",
    "---\n",
    "\n",
    "Load your data from a csv file into a Pandas DataFrame. For other filetypes, consult the Pandas documentation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# file_path = \"D:\\\\Example\\\\File\\\\Path.csv\"\r\n",
    "# df = pd.read_csv(file_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sample data\n",
    "---\n",
    "\n",
    "Generator for a simple Random Walk, for testing purposes. If you have no data use this to generate some. Also provides a baseline to test against."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def sample_data(length):\r\n",
    "    \"\"\"Generates an array of sample data.\"\"\"\r\n",
    "    np.random.seed(1010)  # for baseline consistency\r\n",
    "    random_steps = np.random.choice([-1, 1], length)\r\n",
    "    random_steps[0] = 0  # always start from 0\r\n",
    "    random_walk = np.cumsum(random_steps)\r\n",
    "    return random_walk"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "some_data = sample_data(10000)\r\n",
    "\r\n",
    "f, ax = plt.subplots(figsize=(5, 4))\r\n",
    "ax.plot(some_data)\r\n",
    "ax.set_xlabel('t')\r\n",
    "ax.set_ylabel('x(t)')\r\n",
    "ax.grid(True)\r\n",
    "sns.despine(left=True, bottom=True)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functions\r\n",
    "---\r\n",
    "Will move all of these into a separate script file at a later date..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def apply_stripes(data, stripes, show_plot): \r\n",
    "    \"\"\"\r\n",
    "    Rounds `data` to `stripes` evenly spaced intervals.\r\n",
    "\r\n",
    "    Parameters\r\n",
    "    ----------\r\n",
    "    data : array_like\r\n",
    "        Time-series data to be examined.\r\n",
    "    stripes : int\r\n",
    "        Number of stripes to apply. \r\n",
    "    show_plot : bool\r\n",
    "        If True, show data plot with overlaid stripes.\r\n",
    "\r\n",
    "    Returns\r\n",
    "    ----------\r\n",
    "    rounded_data : ndarray\r\n",
    "        `data` rounded to `stripes` number of equally spaced intervals.\r\n",
    "    \"\"\"\r\n",
    "    \r\n",
    "    if show_plot == True:\r\n",
    "        lines = np.linspace(min(data), max(data), num=stripes)\r\n",
    "        plt.figure(figsize=(5, 4))\r\n",
    "        plt.plot(data)\r\n",
    "        plt.hlines(y=lines, xmin=0, xmax=len(data), colors='0.3', linewidths=1, alpha=0.4)\r\n",
    "        plt.xlabel('t')\r\n",
    "        plt.ylabel('Data(t)')\r\n",
    "        plt.title('Data with stripes')\r\n",
    "        sns.despine()\r\n",
    "        plt.show()\r\n",
    "    \r\n",
    "    if min(data) <= 0:\r\n",
    "        data = data + abs(min(data))\r\n",
    "    elif min(data) > 0:\r\n",
    "        data = data - abs(min(data))\r\n",
    "    max_data = max(data)\r\n",
    "    min_data = min(data)\r\n",
    "    data_width = abs(max_data - min_data)\r\n",
    "    stripe_size = data_width / stripes\r\n",
    "    rounded_data = data / stripe_size\r\n",
    "    return rounded_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def find_events(series):\r\n",
    "    \"\"\"Records an event (1) when `series` changes value.\"\"\"\r\n",
    "    events = []\r\n",
    "    for i in range(1, len(series)):\r\n",
    "        if (series[i] < np.floor(series[i-1])+1 and \r\n",
    "            series[i] > np.ceil(series[i-1])-1):\r\n",
    "            # if both true, no crossing\r\n",
    "            events.append(0)\r\n",
    "        else:\r\n",
    "            events.append(1)\r\n",
    "    np.append(events, 0)\r\n",
    "    return events"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def make_trajectory(events):\r\n",
    "    \"\"\"Constructs diffusion trajectory from events.\"\"\"\r\n",
    "    trajectory = np.cumsum(events)\r\n",
    "    return trajectory"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def entropy(trajectory):\r\n",
    "    \"\"\"\r\n",
    "    Calculates the Shannon Entropy of the diffusion trajectory.\r\n",
    "\r\n",
    "    Generates a range of window lengths L. Steps each one along \r\n",
    "    'trajectory' and computes the displacement of 'trajectory' \r\n",
    "    over each window position. Bins these displacements, and divides \r\n",
    "    by the sum of all bins to make the probability distribution 'p'. \r\n",
    "    Puts 'p' into the equation for Shannon Entropy to get s(L).\r\n",
    "    Repeats for all L in range 'window_lengths'.\r\n",
    "\r\n",
    "    Parameters\r\n",
    "    ----------\r\n",
    "    trajectory : array_like\r\n",
    "        Diffusion trajectory. Constructed by make_trajectory.\r\n",
    "\r\n",
    "    Returns\r\n",
    "    ----------\r\n",
    "    s : ndarray\r\n",
    "        Shannon Entropy values, S(L).\r\n",
    "    window_lengths : ndarray\r\n",
    "        Window lengths, L. \r\n",
    "\r\n",
    "    Notes\r\n",
    "    ----------\r\n",
    "    'tqdm(...)' makes the progress bar appear.\r\n",
    "    \"\"\"\r\n",
    "    S = []\r\n",
    "    window_lengths = np.arange(1, int(0.25*len(trajectory)), 1)\r\n",
    "    for L in tqdm(window_lengths):\r\n",
    "        window_starts = np.arange(0, len(trajectory)-L, 1)\r\n",
    "        window_ends = np.arange(L, len(trajectory), 1)\r\n",
    "        displacements = trajectory[window_ends] - trajectory[window_starts]\r\n",
    "        bin_counts = np.bincount(displacements)\r\n",
    "        bin_counts = bin_counts[bin_counts != 0]\r\n",
    "        P = bin_counts / np.sum(bin_counts)\r\n",
    "        S.append(-np.sum(P * np.log(P)))\r\n",
    "    return S, window_lengths"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def no_stripe_entropy(trajectory):\r\n",
    "    \"\"\"\r\n",
    "    Calculates the Shannon Entropy of the diffusion trajectory.\r\n",
    "\r\n",
    "    Generates a range of window lengths L. Steps each one along \r\n",
    "    'trajectory' and computes the displacement of 'trajectory' \r\n",
    "    over each window position. Bins these displacements, and divides \r\n",
    "    by the sum of all bins to make the probability distribution 'p'. \r\n",
    "    Puts 'p' into the equation for Shannon Entropy to get s(L).\r\n",
    "    Repeats for all L in range 'window_lengths'.\r\n",
    "\r\n",
    "    Parameters\r\n",
    "    ----------\r\n",
    "    trajectory : array_like\r\n",
    "        Diffusion trajectory. FOR NO STRIPES JUST PASS THE DATA SERIES.\r\n",
    "\r\n",
    "    Returns\r\n",
    "    ----------\r\n",
    "    S : ndarray\r\n",
    "        Shannon Entropy values, S(L).\r\n",
    "    window_lengths : ndarray\r\n",
    "        Window lengths, L.\r\n",
    "\r\n",
    "    Notes\r\n",
    "    ----------\r\n",
    "    `tqdm()` makes the progress bar appear.\r\n",
    "    \"\"\"\r\n",
    "    window_lengths = np.arange(1, int(0.25*len(trajectory)), 1)\r\n",
    "    S = []\r\n",
    "    for L in tqdm(window_lengths):\r\n",
    "        window_starts = np.arange(0, len(trajectory)-L, 1)\r\n",
    "        window_ends = np.arange(L, len(trajectory), 1)\r\n",
    "        traj = trajectory[window_starts] - trajectory[window_ends]\r\n",
    "        counts, bin_edge = np.histogram(traj, bins='doane')  # doane least bad for nongaussian\r\n",
    "        counts = np.array(counts[counts != 0])\r\n",
    "        binsize = bin_edge[1] - bin_edge[0]\r\n",
    "        P = counts / sum(counts)\r\n",
    "        S.append(-sum(P*np.log(P)) + np.log(binsize))\r\n",
    "    return S, window_lengths"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_scaling(S, L, start, stop):\r\n",
    "    \"\"\"\r\n",
    "    Calculates scaling.\r\n",
    "    \r\n",
    "    Calculates the scaling of the time-series by performing a \r\n",
    "    least-squares linear fit over S(l) and ln(l).\r\n",
    "\r\n",
    "    Parameters\r\n",
    "    ----------\r\n",
    "    s : array_like\r\n",
    "        Shannon Entropy values. \r\n",
    "    L : array_like\r\n",
    "        Window Lengths. \r\n",
    "    start : int\r\n",
    "        Index at which to start the fit slice.\r\n",
    "    stop : int\r\n",
    "        Index at which to stop the fit slice.\r\n",
    "\r\n",
    "    Returns\r\n",
    "    ----------\r\n",
    "    L_slice : ndarray \r\n",
    "        The slice of window lengths L.\r\n",
    "    coefficients : ndarray\r\n",
    "        Slope and intercept of the fit. \r\n",
    "\r\n",
    "    Notes\r\n",
    "    ----------\r\n",
    "    Least-squares linear fits on log scale data have issues, \r\n",
    "    see doi:10.1371/journal.pone.0085777\r\n",
    "    Making a version that uses the powerlaw package instead \r\n",
    "    would be better...\r\n",
    "    \"\"\"\r\n",
    "    S_slice = S[start:stop]\r\n",
    "    L_slice = L[start:stop]\r\n",
    "    coefficients = np.polyfit(np.log(L_slice), S_slice, 1)\r\n",
    "    return L_slice, coefficients"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_mu(delta):\r\n",
    "    \"\"\"\r\n",
    "    Calculates the mu.\r\n",
    "\r\n",
    "    Parameters\r\n",
    "    ----------\r\n",
    "    delta : float\r\n",
    "        Scaling of the time-series process. \r\n",
    "\r\n",
    "    Returns\r\n",
    "    ----------\r\n",
    "    mu : float\r\n",
    "        Complexity parameter. Powerlaw index for inter-event \r\n",
    "        time distribution.\r\n",
    "    Notes\r\n",
    "    ----------\r\n",
    "    mu is calculated by both rules. later both are plotted\r\n",
    "    against the line relating delta and mu, to hopefully\r\n",
    "    let users graphically determine the correct mu.\r\n",
    "    \"\"\"\r\n",
    "    mu1 = 1 + delta\r\n",
    "    mu2 = 1 + (1 / delta)\r\n",
    "    return mu1, mu2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot_results(L, S, x_interval, slope, y_intercept, mu):\r\n",
    "    \"\"\"testing a plotting function\"\"\"\r\n",
    "    fig, ax = plt.subplots()\r\n",
    "    ax.plot(L, S, linestyle='', marker='.')\r\n",
    "    ax.plot(x_interval, slope * np.log(x_interval) + y_intercept, color='k',\r\n",
    "             label='$\\delta = $'+str(np.round(slope, 2)))\r\n",
    "    ax.plot([], [], linestyle='',label='$\\mu = $'+str(np.round(mu, 2)))\r\n",
    "    return ax"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot_mu_candidates(delta, mu1, mu2):\r\n",
    "    x1 = np.linspace(1, 2, 100)\r\n",
    "    x2 = np.linspace(2, 3, 100)\r\n",
    "    x3 = np.linspace(3, 4, 100)\r\n",
    "    y1 = x1 - 1\r\n",
    "    y2 = 1 / (x2 - 1)\r\n",
    "    y3 = np.full(100, 0.5)\r\n",
    "\r\n",
    "    plt.figure(figsize=(5, 4))\r\n",
    "    plt.plot(x1, y1, color='k')\r\n",
    "    plt.plot(x2, y2, color='k')\r\n",
    "    plt.plot(x3, y3, color='k')\r\n",
    "    plt.plot(mu1, delta,\r\n",
    "             marker='o',\r\n",
    "             label='$\\\\mu$ = '+str(np.round(mu1, 2)))\r\n",
    "    plt.plot(mu2, delta,\r\n",
    "             marker='o',\r\n",
    "             label='$\\\\mu$ = '+str(np.round(mu2, 2)))  \r\n",
    "    plt.xticks(ticks=np.linspace(1, 4, 7))\r\n",
    "    plt.yticks(ticks=np.linspace(0, 1, 5))\r\n",
    "    plt.xlabel('$\\\\mu$')\r\n",
    "    plt.ylabel('$\\\\delta$')\r\n",
    "    plt.legend(loc=0)\r\n",
    "    plt.grid(True)\r\n",
    "    sns.despine(left=True, bottom=True)\r\n",
    "    # plt.show()\r\n",
    "    return None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def dea_no_stripes(data, start, stop):\r\n",
    "    \"\"\"\r\n",
    "    Applies DEA without the stripes refinement.\r\n",
    "\r\n",
    "    Original DEA. Takes the original time series as the diffusion \r\n",
    "    trajectory.\r\n",
    "\r\n",
    "    Parameters\r\n",
    "    ----------\r\n",
    "    data : array_like\r\n",
    "        Time-series to be analysed.\r\n",
    "    start : int\r\n",
    "        Array index at which to start linear fit.\r\n",
    "    stop : int \r\n",
    "        Array index at which to stop linear fit.\r\n",
    "\r\n",
    "    Returns\r\n",
    "    ----------\r\n",
    "    figure \r\n",
    "        A figure plotting S(l) vs. ln(l), overlaid with the fit \r\n",
    "        line, labelled with the scaling and mu values.\r\n",
    "    \"\"\"\r\n",
    "    S, L = no_stripe_entropy(data)\r\n",
    "    fit = get_scaling(S, L, start, stop)\r\n",
    "    mu = get_mu(fit[1][0])\r\n",
    "\r\n",
    "    plt.figure(figsize=(5, 4))\r\n",
    "    plt.plot(L, S, linestyle='', marker='.')\r\n",
    "    plt.plot(fit[0], fit[1][0] * np.log(fit[0]) + fit[1][1], color='k',\r\n",
    "             label='$\\delta = {}$'.format(np.round(fit[1][0], 2)))\r\n",
    "    plt.plot([], [], linestyle='', \r\n",
    "             label='$\\mu = {}$'.format(np.round(mu, 2)))\r\n",
    "    plt.xscale('log')\r\n",
    "    plt.xlabel('$ln(l)$')\r\n",
    "    plt.ylabel('$S(l)$')\r\n",
    "    plt.legend(loc=0)\r\n",
    "    plt.grid(True)\r\n",
    "    sns.despine(left=True, bottom=True)\r\n",
    "    # plt.show()\r\n",
    "    return None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def dea_with_stripes(data, stripes, start, stop, data_plot):\r\n",
    "    \"\"\"\r\n",
    "    Applies DEA with the stripes refinement.\r\n",
    "\r\n",
    "    Runs a sequence of functions to apply stripes and then \r\n",
    "    perform DEA on the data series. \r\n",
    "\r\n",
    "    Parameters\r\n",
    "    ----------\r\n",
    "    data : array_like\r\n",
    "        Time-series to be analysed.\r\n",
    "    stripes : int\r\n",
    "        Number of stripes to be applied to the data.\r\n",
    "    start : int\r\n",
    "        Array index at which to start linear fit.\r\n",
    "    stop : int \r\n",
    "        Array index at which to stop linear fit.\r\n",
    "    data_plot : bool\r\n",
    "        If True, show data plot with overlaid stripes.\r\n",
    "\r\n",
    "    Returns\r\n",
    "    ----------\r\n",
    "    fig : figure \r\n",
    "        A figure plotting S(l) vs. ln(l), overlaid with the fit \r\n",
    "        line, labelled with the scaling and mu values.\r\n",
    "    \"\"\"\r\n",
    "    rounded_data = apply_stripes(data, stripes, data_plot)\r\n",
    "    event_array = find_events(rounded_data)\r\n",
    "    diffusion_trajectory = make_trajectory(event_array)\r\n",
    "    s, L = entropy(diffusion_trajectory)\r\n",
    "    fit = get_scaling(s, L, start, stop)\r\n",
    "    mu = get_mu(fit[1][0])\r\n",
    "\r\n",
    "    plt.figure(figsize=(5, 4))\r\n",
    "    plt.plot(L, s, linestyle='', marker='.')\r\n",
    "    plt.plot(fit[0], fit[1][0] * np.log(fit[0]) + fit[1][1], color='k',\r\n",
    "             label='$\\delta = $'+str(np.round(fit[1][0], 2)))\r\n",
    "    plt.xscale('log')\r\n",
    "    plt.xlabel('$ln(L)$')\r\n",
    "    plt.ylabel('$S(L)$')\r\n",
    "    plt.legend(loc=0)\r\n",
    "    plt.grid(True, which='major')\r\n",
    "    # plt.grid(True, which='minor', linewidth=0.4)\r\n",
    "    sns.despine(left=True, bottom=True)\r\n",
    "    # plt.show()\r\n",
    "\r\n",
    "    plt.figure(figsize=(5, 4))\r\n",
    "    check_mus_plot = plot_mu_candidates(fit[1][0], mu[0], mu[1])\r\n",
    "    return None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Work Cell\n",
    "---\n",
    "\n",
    "Everything you need to work with is in this cell.  \n",
    "\n",
    "### Running  \n",
    " - Load your data into the `data` variable. Numpy arrays or Pandas DataFrame columns will work.  \n",
    " - Choose the number of stripes to apply, and the interval (slice) over which to fit.  \n",
    " - Run!  \n",
    " - Adjust `number_of_stripes` and slicing indexes, `fit_start` and `fit_stop`, as necessary.  \n",
    "\n",
    "### Output  \n",
    " - A progress bar will display progress and time elapsed/remaining.  \n",
    " - On completion, two figures will be drawn with the results:\n",
    "   - One will be of $S(l)$ vs. $ln(l)$, with the slope fit overlaid. This is the main result.\n",
    "   - The other will be a display of the two possible values for $\\mu$, drawn on a graph of the analytical behavior of $\\delta$ vs. $\\mu$. This is to help you determine which $\\mu$ value is right.\n",
    " - Interpretation of results has its own section, below.  \n",
    "\n",
    "### Choosing number of stripes  \n",
    " - Run a few initial tests with different values. e.g. 10, 50, 100.  \n",
    " - If there is significant disagreement in the scalings measured, vary about those trial numbers.  \n",
    " - The correct number of stripes to use is that number such that when varied up or down a little, the scaling does not change.\n",
    " - Rigorous rules for this are still being developed...  \n",
    "\n",
    "### Choosing fit interval  \n",
    " - In the result figure, if the results are good, there will be a region in the loglog figure that appears linear. You want the fit interval to line up with this region.  \n",
    " - $S(l)$ is logged in calculation, $l$ is logged by the scale of the plot. The fitting function accounts for this.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### ----WORK HERE---- ###\r\n",
    "data = sample_data(10000)\r\n",
    "number_of_stripes = 40  # needs to be at least 2\r\n",
    "fit_start = 30\r\n",
    "fit_stop = 500\r\n",
    "show_data_plot = False  # make True to see plot of data with stripes\r\n",
    "\r\n",
    "result = dea_with_stripes(data, number_of_stripes, fit_start, fit_stop, show_data_plot)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Without stripes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# no_stripe_result = dea_no_stripes(data, start=50, stop=500)\r\n",
    "# plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Interpreting Results\n",
    "---\n",
    "\n",
    "### Basics  \n",
    " - $\\delta$ is the measured scaling of the time-series process.  \n",
    " - $\\mu$ is a complexity index, defined as the power for the inter-event time distribution $1/\\tau^{\\mu}$ ($\\tau$ being inter-event time).  \n",
    "\n",
    "### Baselines  \n",
    " - For a totally random process, DEA yields $\\delta = 0.5.$  \n",
    " - The closer $\\delta$ is to 1, and the closer $\\mu$ is to 2, the more complex the data-series is. Those are the critical values of $\\delta$ and $\\mu$.  \n",
    " - If $\\delta < 0.5$, this usually means the time-series is not complex. At least, not in this sense. \n",
    "\n",
    "### Determining $\\mu$  \n",
    " - Two ways of calculating $\\mu$ are employed:  \n",
    "   - For $1 < \\mu < 2$: $\\mu = 1 + \\delta$.  \n",
    "   - For $2 < \\mu < 3$: $\\mu = 1 + 1/\\delta$.  \n",
    " - The correct calculation for $\\mu$ varies. As rigorous rules for determining which is correct in what situation have yet to be laid down, both candidates are calculated and plotted so that the user may compare them. Typically the correct value for $\\mu$ will lie along the line, as the line represents the theoretical relationship.\n",
    " - If you already have an expectation for what range $\\mu$ should be in, e.g. from theoretical arguments, use that.\n",
    " - The theoretical justifications for the two methods of deriving $\\mu$ from the scaling $\\delta$ are given in Section 3.2 of Reference 1 and Section 3.1-3.2 of Reference 3."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Advanced use\n",
    "---\n",
    "\n",
    "\n",
    "### Speed and runtime\n",
    "In the function `entropy()` the range of window lengths $l$ is defined such that each is 1 larger than the previous:  \n",
    "        \n",
    "        window_lengths = np.arange(1, int(0.25*len(trajectory)), 1)  \n",
    "\n",
    "This can make the program take a long time to run if you give it a long time-series (e.g. 20000 timesteps takes ~1 second). If you want to speed up the runtime, you can increase the step size for the range, e.g.:\n",
    "\n",
    "        window_lengths = np.arange(1, int(0.25*len(trajectory)), 10)  \n",
    "\n",
    "This will still give good results, for long time-series, but can greatly speed up runtime.\n",
    "\n",
    "Doing this also means you will have fewer values of $S(l)$ and $ln(l)$ to work with though, so be mindful.\n",
    "\n",
    "\n",
    "### Maximum window length\n",
    "In the function `entropy()` the range of window lengths ends at 0.25 times the length of the diffusion trajectory:\n",
    "\n",
    "        window_lengths = np.arange(1, int(0.25*len(trajectory)), 10)  \n",
    "\n",
    "You can increase further if you want, but there is usually no need. For longer window lengths $l$, and especially for $l$ longer than `0.5*len(trajectory)`, $S(l)$ quickly starts to decay and doesn't give anything useful. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## References\n",
    "---\n",
    " 1. Culbreth, G., West, B. J., & Grigolini, P. (2019). Entropic approach to the detection of crucial events. *Entropy*, *21*(2), 178. [doi:10.3390/e21020178](https://doi.org/10.3390/e21020178)\n",
    "    - This paper introduced the stripes and describes their role with figure examples.\n",
    "    - Note: this paper used $\\eta$ to denote scaling, rather than $\\delta$.  \n",
    "\n",
    " 2. Scafetta, N., & Grigolini, P. (2002). Scaling detection in time series: diffusion entropy analysis. *Physical Review E*, *66*(3), 036130. [doi:10.1103/PhysRevE.66.036130](https://doi.org/10.1103/PhysRevE.66.036130)\n",
    "    - The actual algorithm for DEA is detailed (mostly only in words) in Section IV.\n",
    "\n",
    " 3. Grigolini, P., Palatella, L., & Raffaelli, G. (2001). Asymmetric anomalous diffusion: an efficient way to detect memory in time series. *Fractals*, *9*(04), 439-449. [doi:10.1142/S0218348X01000865](https://doi.org/10.1142/S0218348X01000865)\n",
    "    - This paper introduced always using positive steps when constructing the event array, rather than the sign of the step at that time index."
   ],
   "metadata": {}
  }
 ]
}